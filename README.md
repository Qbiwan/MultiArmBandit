# WIP
## Reinforcement Learning: Multi-Arm Bandit
### Exploration vs Exploitation: changing the value of epsilon 
1000 steps


<img src="image/epsilon_compare.png" width="1000" height="400" />

10000 steps


<img src="image/epsilon_compare10000steps.png" width="1000" height="400" />

---
### Non-stationary reward

<img src="image/non_stationary.png" width="1000" height="400" />

---
### Optimistic initial value

<img src="image/optimistic_initial_value.png" width="1000" height="400" />

---
### Upper Confidence Bound

<img src="image/upper_confidence_bound.png" width="1000" height="400" />